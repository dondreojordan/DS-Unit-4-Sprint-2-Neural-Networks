{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import ReLU, Softmax\n",
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "def load_quickdraw10(path):\n",
    "\n",
    "    arr = np.load(path)\n",
    "    X = arr['arr_0']\n",
    "    y = arr['arr_1']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size = 0.80, test_size=0.10, random_state=42)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_quickdraw10('quickdraw10.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early-Stopping (Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/2425 [..............................] - ETA: 2:53 - loss: 146.8583 - accuracy: 0.0909WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.1416s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 2.2594 - accuracy: 0.4061 - val_loss: 1.5616 - val_accuracy: 0.5017\n",
      "Epoch 2/5\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.5487 - accuracy: 0.5167 - val_loss: 1.4748 - val_accuracy: 0.5305\n",
      "Epoch 3/5\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.4645 - accuracy: 0.5422 - val_loss: 1.6308 - val_accuracy: 0.5645\n",
      "Epoch 4/5\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.4421 - accuracy: 0.5549 - val_loss: 1.4867 - val_accuracy: 0.5693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08b4724208>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "logdir = os.path.join(\"logs\", \"test_main\", \"test_subfolder\")\n",
    "# How to structure folders inside a log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delete above. ^^ Is a test folder.\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Early_Stopping\", \"434-EarlyStop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "   1/2425 [..............................] - ETA: 0s - loss: 178.4852 - accuracy: 0.0909WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0385s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 2.2850 - accuracy: 0.4141 - val_loss: 1.6159 - val_accuracy: 0.4861\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.5752 - accuracy: 0.4917 - val_loss: 1.5118 - val_accuracy: 0.4924\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.5347 - accuracy: 0.5111 - val_loss: 1.5761 - val_accuracy: 0.5200\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.4950 - accuracy: 0.5306 - val_loss: 1.5015 - val_accuracy: 0.5100\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.4666 - accuracy: 0.5534 - val_loss: 1.5095 - val_accuracy: 0.5679\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:08 - loss: 129.5674 - accuracy: 0.0758WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0542s). Check your callbacks.\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 1.6240 - accuracy: 0.7012 - val_loss: 0.9194 - val_accuracy: 0.7528\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8274 - accuracy: 0.7774 - val_loss: 0.8079 - val_accuracy: 0.7785\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.7690 - accuracy: 0.7935 - val_loss: 0.7796 - val_accuracy: 0.7877\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7278 - accuracy: 0.8009 - val_loss: 0.7223 - val_accuracy: 0.7967\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7038 - accuracy: 0.8090 - val_loss: 0.7535 - val_accuracy: 0.7972\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:06 - loss: 136.0951 - accuracy: 0.1515WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0537s). Check your callbacks.\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.7995 - accuracy: 0.6839 - val_loss: 1.1930 - val_accuracy: 0.6856\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.0508 - accuracy: 0.7439 - val_loss: 1.0031 - val_accuracy: 0.7363\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9531 - accuracy: 0.7639 - val_loss: 0.9214 - val_accuracy: 0.7690\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.8561 - accuracy: 0.7769 - val_loss: 0.9368 - val_accuracy: 0.7737\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7956 - accuracy: 0.7873 - val_loss: 0.8510 - val_accuracy: 0.7804\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7696 - accuracy: 0.7919 - val_loss: 0.7928 - val_accuracy: 0.7932\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7390 - accuracy: 0.7992 - val_loss: 0.8253 - val_accuracy: 0.7818\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7159 - accuracy: 0.8022 - val_loss: 0.8039 - val_accuracy: 0.7898\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:08 - loss: 75.2757 - accuracy: 0.1212WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0542s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.3251 - accuracy: 0.7090 - val_loss: 0.8054 - val_accuracy: 0.7734\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8348 - accuracy: 0.7826 - val_loss: 0.7831 - val_accuracy: 0.7835\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7816 - accuracy: 0.7944 - val_loss: 0.7746 - val_accuracy: 0.7877\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7506 - accuracy: 0.8022 - val_loss: 0.8016 - val_accuracy: 0.7884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08c99c7be0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Early_Stopping\", \"434-EarlyStop\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "model_earlystop = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(), input_dim=784), \n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "\n",
    "model_earlystop.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_earlystop.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "\n",
    "# Include Hidden Layer\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Early_Stopping\", \"434-EarlyStop_Add_Layer\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "param_model_earlystop_addlayer = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "\n",
    "param_model_earlystop_addlayer.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_earlystop_addlayer.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "    \n",
    "# Include Param (negative slope)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Early_Stopping\", \"434-EarlyStop_Neg_Slope\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "param_model_earlystop_negslope = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "\n",
    "param_model_earlystop_negslope.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_earlystop_negslope.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "    \n",
    "# Include Param (negative slope and learning rate and a hidden layer)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Early_Stopping\", \"434-EarlyStop_All_Params\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "param_model_earlystop_allparams = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "\n",
    "param_model_earlystop_allparams.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(learning_rate=.00105),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_earlystop_allparams.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()  # Change variable \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8386), started 2:19:07 ago. (Use '!kill 8386' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-730dab42384a1d87\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-730dab42384a1d87\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include learning rate = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "   1/2425 [..............................] - ETA: 0s - loss: 137.3750 - accuracy: 0.2121WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0423s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 2.2834 - accuracy: 0.3894 - val_loss: 1.6357 - val_accuracy: 0.4760\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.6240 - accuracy: 0.4966 - val_loss: 1.5612 - val_accuracy: 0.5214\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.5050 - accuracy: 0.5303 - val_loss: 1.4769 - val_accuracy: 0.5361\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 1.4229 - accuracy: 0.5551 - val_loss: 1.4214 - val_accuracy: 0.5690\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.3561 - accuracy: 0.5843 - val_loss: 1.3567 - val_accuracy: 0.5855\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.2381 - accuracy: 0.6172 - val_loss: 1.2505 - val_accuracy: 0.6153\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.1493 - accuracy: 0.6431 - val_loss: 1.2177 - val_accuracy: 0.6376\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.1145 - accuracy: 0.6651 - val_loss: 1.1887 - val_accuracy: 0.6584\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.0637 - accuracy: 0.6920 - val_loss: 1.1301 - val_accuracy: 0.7106\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.0067 - accuracy: 0.7254 - val_loss: 1.0592 - val_accuracy: 0.7039\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9777 - accuracy: 0.7374 - val_loss: 0.9935 - val_accuracy: 0.7323\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9556 - accuracy: 0.7427 - val_loss: 1.0158 - val_accuracy: 0.7400\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9382 - accuracy: 0.7476 - val_loss: 0.9782 - val_accuracy: 0.7489\n",
      "Epoch 14/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9101 - accuracy: 0.7553 - val_loss: 0.9892 - val_accuracy: 0.7571\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:13 - loss: 81.0891 - accuracy: 0.0758WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0590s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 2.0418 - accuracy: 0.4747 - val_loss: 1.2260 - val_accuracy: 0.6237\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.1777 - accuracy: 0.6437 - val_loss: 1.1512 - val_accuracy: 0.6588\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.0817 - accuracy: 0.6721 - val_loss: 1.0362 - val_accuracy: 0.6965\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.0181 - accuracy: 0.6962 - val_loss: 1.0538 - val_accuracy: 0.6953\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.9810 - accuracy: 0.7222 - val_loss: 0.9853 - val_accuracy: 0.7166\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 6s 3ms/step - loss: 0.9359 - accuracy: 0.7379 - val_loss: 0.9340 - val_accuracy: 0.7358\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 6s 3ms/step - loss: 0.9089 - accuracy: 0.7456 - val_loss: 0.9374 - val_accuracy: 0.7430\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.8802 - accuracy: 0.7560 - val_loss: 0.8972 - val_accuracy: 0.7603\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8651 - accuracy: 0.7638 - val_loss: 0.8952 - val_accuracy: 0.7474\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8686 - accuracy: 0.7627 - val_loss: 0.9256 - val_accuracy: 0.7571\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.8356 - accuracy: 0.7661 - val_loss: 0.8789 - val_accuracy: 0.7491\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8142 - accuracy: 0.7679 - val_loss: 0.8769 - val_accuracy: 0.7684\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7898 - accuracy: 0.7785 - val_loss: 0.8608 - val_accuracy: 0.7655\n",
      "Epoch 14/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7703 - accuracy: 0.7874 - val_loss: 0.8414 - val_accuracy: 0.7644\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:10 - loss: 111.7824 - accuracy: 0.1061WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.3373 - accuracy: 0.7040 - val_loss: 0.8647 - val_accuracy: 0.7701\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8505 - accuracy: 0.7756 - val_loss: 0.8694 - val_accuracy: 0.7659\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7907 - accuracy: 0.7916 - val_loss: 0.8022 - val_accuracy: 0.7883\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7562 - accuracy: 0.7987 - val_loss: 0.8165 - val_accuracy: 0.7859\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7341 - accuracy: 0.8046 - val_loss: 0.8559 - val_accuracy: 0.7785\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.7079 - accuracy: 0.8091 - val_loss: 0.7365 - val_accuracy: 0.8022\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.6897 - accuracy: 0.8100 - val_loss: 0.7688 - val_accuracy: 0.7993\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.6796 - accuracy: 0.8147 - val_loss: 0.7685 - val_accuracy: 0.7967\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.6763 - accuracy: 0.8167 - val_loss: 0.7262 - val_accuracy: 0.8066\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6682 - accuracy: 0.8191 - val_loss: 0.7671 - val_accuracy: 0.7964\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.6563 - accuracy: 0.8203 - val_loss: 0.7436 - val_accuracy: 0.8012\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.6553 - accuracy: 0.8233 - val_loss: 0.7582 - val_accuracy: 0.8005\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:09 - loss: 72.7067 - accuracy: 0.1364WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0558s). Check your callbacks.\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.3270 - accuracy: 0.7155 - val_loss: 0.9299 - val_accuracy: 0.7592\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8276 - accuracy: 0.7817 - val_loss: 0.7685 - val_accuracy: 0.7800\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7607 - accuracy: 0.7949 - val_loss: 0.8734 - val_accuracy: 0.7465\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7335 - accuracy: 0.8020 - val_loss: 0.7526 - val_accuracy: 0.7963\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6985 - accuracy: 0.8095 - val_loss: 0.7957 - val_accuracy: 0.7864\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6797 - accuracy: 0.8138 - val_loss: 0.8124 - val_accuracy: 0.7821\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6747 - accuracy: 0.8177 - val_loss: 0.7365 - val_accuracy: 0.8013\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.6639 - accuracy: 0.8177 - val_loss: 0.7467 - val_accuracy: 0.8034\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6577 - accuracy: 0.8211 - val_loss: 0.8051 - val_accuracy: 0.7956\n",
      "Epoch 10/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.6561 - accuracy: 0.8233 - val_loss: 0.7030 - val_accuracy: 0.8144\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6455 - accuracy: 0.8253 - val_loss: 0.7481 - val_accuracy: 0.8126\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6369 - accuracy: 0.8257 - val_loss: 0.7945 - val_accuracy: 0.7997\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.6375 - accuracy: 0.8270 - val_loss: 0.7970 - val_accuracy: 0.8076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08ec0d8c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Dropout\", \"434-EarlyStop_WeightConstraint_Dropout\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "model_dropout = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(), input_dim=784), \n",
    "    Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "model_dropout.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_dropout.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "\n",
    "# Include Hidden Layer\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Dropout\", \"434-EarlyStop_WeightConstraint_Dropout_Add_Layer\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_dropout_addlayer = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(), input_dim=784),\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU()),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "\n",
    "param_model_dropout_addlayer.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_dropout_addlayer.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "\n",
    "# Include Param (negative slope)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Dropout\", \"434-EarlyStop_WeightConstraint_Dropout_Neg_Slope\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_dropout_negslope = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "param_model_dropout_negslope.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "param_model_dropout_negslope.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "    \n",
    "# Include Param (negative slope and learning rate and a hidden layer)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Dropout\", \"434-EarlyStop_WeightConstraint_Dropout_All_Params\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_dropout_allparams = tf.keras.Sequential([\n",
    "    Dense(32, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, activation=Softmax())\n",
    "    ])\n",
    "param_model_dropout_allparams = tf.keras.Sequential([\n",
    ".compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(learning_rate=.00105),\n",
    "              metrics=['accuracy'])\n",
    "param_model_dropout_allparams = tf.keras.Sequential([\n",
    ".fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()  # Change variable \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eef79ea8cf3416a6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eef79ea8cf3416a6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Decay\n",
    "```python\n",
    "Dense(64, input_dim=64,\n",
    "            kernel_regularizer=regularizers.l2(0.01),\n",
    "            activity_regularizer=regularizers.l1(0.01)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "   1/2425 [..............................] - ETA: 0s - loss: 113.8924 - accuracy: 0.0606WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0436s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.7844 - accuracy: 0.5988 - val_loss: 0.9412 - val_accuracy: 0.7585\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9319 - accuracy: 0.7546 - val_loss: 0.9560 - val_accuracy: 0.7524\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9358 - accuracy: 0.7673 - val_loss: 1.1574 - val_accuracy: 0.7337\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9730 - accuracy: 0.7712 - val_loss: 1.0446 - val_accuracy: 0.7620\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:12 - loss: 76.7408 - accuracy: 0.1515WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0558s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.8957 - accuracy: 0.7020 - val_loss: 1.1395 - val_accuracy: 0.7521\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.9680 - accuracy: 0.7679 - val_loss: 0.9208 - val_accuracy: 0.7595\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8304 - accuracy: 0.7911 - val_loss: 0.8517 - val_accuracy: 0.7885\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.7959 - accuracy: 0.8005 - val_loss: 0.8004 - val_accuracy: 0.7945\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8023 - accuracy: 0.8018 - val_loss: 0.7850 - val_accuracy: 0.8082\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8087 - accuracy: 0.8048 - val_loss: 0.8442 - val_accuracy: 0.7865\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8154 - accuracy: 0.8062 - val_loss: 0.7833 - val_accuracy: 0.8209\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8225 - accuracy: 0.8077 - val_loss: 0.9725 - val_accuracy: 0.7772\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:02 - loss: 101.3660 - accuracy: 0.1364WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0496s). Check your callbacks.\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 1.8250 - accuracy: 0.7007 - val_loss: 1.0219 - val_accuracy: 0.7689\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9590 - accuracy: 0.7657 - val_loss: 0.8761 - val_accuracy: 0.7767\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8304 - accuracy: 0.7904 - val_loss: 0.7979 - val_accuracy: 0.7995\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.7997 - accuracy: 0.7998 - val_loss: 0.8224 - val_accuracy: 0.7946\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8001 - accuracy: 0.8040 - val_loss: 0.7889 - val_accuracy: 0.8071\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8097 - accuracy: 0.8061 - val_loss: 0.8627 - val_accuracy: 0.7906\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:13 - loss: 75.8095 - accuracy: 0.1818WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0589s). Check your callbacks.\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.9372 - accuracy: 0.6843 - val_loss: 1.1474 - val_accuracy: 0.7633\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.1129 - accuracy: 0.7725 - val_loss: 1.0475 - val_accuracy: 0.7810\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.0439 - accuracy: 0.7765 - val_loss: 1.0383 - val_accuracy: 0.7492\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9620 - accuracy: 0.7831 - val_loss: 1.0229 - val_accuracy: 0.7629\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9324 - accuracy: 0.7867 - val_loss: 0.9538 - val_accuracy: 0.7788\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.9073 - accuracy: 0.7923 - val_loss: 0.9654 - val_accuracy: 0.7638\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8916 - accuracy: 0.7983 - val_loss: 0.9014 - val_accuracy: 0.7961\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8739 - accuracy: 0.8039 - val_loss: 0.9411 - val_accuracy: 0.7837\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.8762 - accuracy: 0.8057 - val_loss: 0.8884 - val_accuracy: 0.8053\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8675 - accuracy: 0.8076 - val_loss: 0.8950 - val_accuracy: 0.7970\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8734 - accuracy: 0.8101 - val_loss: 0.9039 - val_accuracy: 0.8039\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8745 - accuracy: 0.8091 - val_loss: 0.8519 - val_accuracy: 0.8177\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 4s 2ms/step - loss: 0.8772 - accuracy: 0.8094 - val_loss: 0.9070 - val_accuracy: 0.8043\n",
      "Epoch 14/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8794 - accuracy: 0.8109 - val_loss: 0.9347 - val_accuracy: 0.7839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08c8445978>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras import regularizers\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_L2_WeightDecay\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "model_weightdecay = tf.keras.Sequential([\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(), input_dim=784), \n",
    "    Dense(10, kernel_regularizer=regularizers.l2(0.01), activation=Softmax())\n",
    "    ])\n",
    "\n",
    "model_weightdecay.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_weightdecay.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "# Include Hidden Layer\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_L2_WeightDecay_Add_Layer\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "param_model_weightdecay_addlayer = tf.keras.Sequential([\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, kernel_regularizer=regularizers.l2(0.01), activation=Softmax())\n",
    "    ])\n",
    "param_model_weightdecay_addlayer.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "param_model_weightdecay_addlayer.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "# Include Param (negative slope)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_L2_WeightDecay_Neg_Slope\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "param_model_weightdecay_negslope = tf.keras.Sequential([\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01),\n",
    "    Dense(10, kernel_regularizer=regularizers.l2(0.01), activation=Softmax())\n",
    "    ])\n",
    "param_model_weightdecay_negslope.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "param_model_weightdecay_negslope.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "    \n",
    "    \n",
    "# Include Param (negative slope and learning rate and a hidden layer)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_L2_WeightDecay_All_Params\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "    \n",
    "param_model_weightdecay_allparams = tf.keras.Sequential([\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, kernel_regularizer=regularizers.l2(0.01), activation=ReLU(negative_slope=.01),\n",
    "    Dense(10, kernel_regularizer=regularizers.l2(0.01), activation=Softmax())\n",
    "    ])\n",
    "param_model_weightdecay_allparams.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(learning_rate=.00105),\n",
    "              metrics=['accuracy'])\n",
    "param_model_weightdecay_allparams.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()  # Change variable \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Constraints\n",
    "```python\n",
    "tf.keras.constraints.MaxNorm(\n",
    "    max_value=2, axis=0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include learning rate = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:14 - loss: 124.0821 - accuracy: 0.1667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0590s). Check your callbacks.\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 2.2603 - accuracy: 0.4242 - val_loss: 1.5840 - val_accuracy: 0.4991\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.5891 - accuracy: 0.5261 - val_loss: 1.4299 - val_accuracy: 0.5467\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 6s 3ms/step - loss: 1.4852 - accuracy: 0.5612 - val_loss: 1.4817 - val_accuracy: 0.5762\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 1.3920 - accuracy: 0.5938 - val_loss: 1.3908 - val_accuracy: 0.6097\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 1.2489 - accuracy: 0.6451 - val_loss: 1.2392 - val_accuracy: 0.6570\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.1336 - accuracy: 0.6726 - val_loss: 1.2381 - val_accuracy: 0.6720\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.0834 - accuracy: 0.6878 - val_loss: 1.0753 - val_accuracy: 0.6777\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 6s 3ms/step - loss: 1.0551 - accuracy: 0.6943 - val_loss: 1.1656 - val_accuracy: 0.6857\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 6s 3ms/step - loss: 1.0127 - accuracy: 0.7070 - val_loss: 1.0387 - val_accuracy: 0.6917\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.9587 - accuracy: 0.7309 - val_loss: 0.9949 - val_accuracy: 0.7229\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9158 - accuracy: 0.7438 - val_loss: 0.9707 - val_accuracy: 0.7244\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.9002 - accuracy: 0.7475 - val_loss: 1.1134 - val_accuracy: 0.7041\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8991 - accuracy: 0.7484 - val_loss: 0.9876 - val_accuracy: 0.7217\n",
      "Epoch 14/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 0.8883 - accuracy: 0.7552 - val_loss: 0.9695 - val_accuracy: 0.7466\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:31 - loss: 63.9667 - accuracy: 0.0606WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0731s). Check your callbacks.\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 1.6840 - accuracy: 0.5479 - val_loss: 1.2914 - val_accuracy: 0.6644\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 5s 2ms/step - loss: 1.1160 - accuracy: 0.6714 - val_loss: 1.0157 - val_accuracy: 0.7009\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 6s 2ms/step - loss: 0.9842 - accuracy: 0.7252 - val_loss: 0.9577 - val_accuracy: 0.7285\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.8802 - accuracy: 0.7571 - val_loss: 0.8491 - val_accuracy: 0.7752\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.8114 - accuracy: 0.7753 - val_loss: 0.8386 - val_accuracy: 0.7805\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.7553 - accuracy: 0.7891 - val_loss: 0.7536 - val_accuracy: 0.7978\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.7321 - accuracy: 0.7951 - val_loss: 0.6889 - val_accuracy: 0.8015\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.7125 - accuracy: 0.8043 - val_loss: 0.7378 - val_accuracy: 0.7936\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6950 - accuracy: 0.8099 - val_loss: 0.9223 - val_accuracy: 0.7939\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6863 - accuracy: 0.8132 - val_loss: 0.7762 - val_accuracy: 0.7860\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 1:55 - loss: 75.7894 - accuracy: 0.0909WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.0883s). Check your callbacks.\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 1.3751 - accuracy: 0.7081 - val_loss: 0.8894 - val_accuracy: 0.7647\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.8248 - accuracy: 0.7831 - val_loss: 0.8245 - val_accuracy: 0.7790\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.7568 - accuracy: 0.7994 - val_loss: 0.7803 - val_accuracy: 0.7845\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.7279 - accuracy: 0.8042 - val_loss: 0.7154 - val_accuracy: 0.8034\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.7106 - accuracy: 0.8091 - val_loss: 0.7621 - val_accuracy: 0.7938\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6908 - accuracy: 0.8132 - val_loss: 0.6945 - val_accuracy: 0.8029\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6732 - accuracy: 0.8160 - val_loss: 0.6845 - val_accuracy: 0.8097\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6635 - accuracy: 0.8189 - val_loss: 0.7073 - val_accuracy: 0.8133\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6547 - accuracy: 0.8193 - val_loss: 0.6688 - val_accuracy: 0.8167\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6507 - accuracy: 0.8204 - val_loss: 0.6571 - val_accuracy: 0.8169\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6449 - accuracy: 0.8224 - val_loss: 0.6364 - val_accuracy: 0.8154\n",
      "Epoch 12/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6415 - accuracy: 0.8238 - val_loss: 0.6731 - val_accuracy: 0.8064\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6355 - accuracy: 0.8253 - val_loss: 0.6606 - val_accuracy: 0.8160\n",
      "Epoch 14/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6290 - accuracy: 0.8253 - val_loss: 0.6673 - val_accuracy: 0.8106\n",
      "Epoch 1/14\n",
      "   2/2425 [..............................] - ETA: 2:09 - loss: 138.8534 - accuracy: 0.0909WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.1045s). Check your callbacks.\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 1.4305 - accuracy: 0.7069 - val_loss: 0.8369 - val_accuracy: 0.7615\n",
      "Epoch 2/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.8245 - accuracy: 0.7805 - val_loss: 0.8064 - val_accuracy: 0.7731\n",
      "Epoch 3/14\n",
      "2425/2425 [==============================] - 10s 4ms/step - loss: 0.7664 - accuracy: 0.7927 - val_loss: 0.7935 - val_accuracy: 0.7928\n",
      "Epoch 4/14\n",
      "2425/2425 [==============================] - 9s 4ms/step - loss: 0.7401 - accuracy: 0.7999 - val_loss: 0.7709 - val_accuracy: 0.7880\n",
      "Epoch 5/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.7162 - accuracy: 0.8050 - val_loss: 0.7592 - val_accuracy: 0.7943\n",
      "Epoch 6/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6969 - accuracy: 0.8095 - val_loss: 0.7413 - val_accuracy: 0.7954\n",
      "Epoch 7/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6839 - accuracy: 0.8119 - val_loss: 0.6960 - val_accuracy: 0.8130\n",
      "Epoch 8/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6691 - accuracy: 0.8157 - val_loss: 0.6887 - val_accuracy: 0.8056\n",
      "Epoch 9/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6580 - accuracy: 0.8166 - val_loss: 0.7024 - val_accuracy: 0.8087\n",
      "Epoch 10/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6497 - accuracy: 0.8188 - val_loss: 0.6740 - val_accuracy: 0.8117\n",
      "Epoch 11/14\n",
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6476 - accuracy: 0.8198 - val_loss: 0.6860 - val_accuracy: 0.8156\n",
      "Epoch 12/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425/2425 [==============================] - 8s 3ms/step - loss: 0.6422 - accuracy: 0.8199 - val_loss: 0.7045 - val_accuracy: 0.8150\n",
      "Epoch 13/14\n",
      "2425/2425 [==============================] - 7s 3ms/step - loss: 0.6366 - accuracy: 0.8212 - val_loss: 0.7213 - val_accuracy: 0.7973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08bc1dec50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_WeightConstraint\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "model_weightconstraint = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(), input_dim=784), \n",
    "    Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "model_weightconstraint.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_weightconstraint.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "# Include Hidden Layer\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_WeightConstraint_Add_Layer\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_weightconstraint_addlayer = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(), input_dim=784),\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU()),\n",
    "    Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "param_model_weightconstraint_addlayer.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_weightconstraint_addlayer.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "\n",
    "# Include Param (negative slope)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_WeightConstraint_Neg_Slope\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_weightconstraint_negslope = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "param_model_weightconstraint_negslope.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_weightconstraint_negslope.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])\n",
    "\n",
    "# Include Param (negative slope and learning rate and a hidden layer)\n",
    "logdir = os.path.join(\"logs\", \"Deploy_Assignment\", \"Weight_Decay\", \"434-EarlyStop_WeightConstraint_All_Params\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                    logdir, \n",
    "                                                    histogram_freq=1\n",
    "                                                    )\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3)\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "param_model_weightconstraint_allparams = tf.keras.Sequential([\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "    Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01)),\n",
    "    Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "    ])\n",
    "\n",
    "param_model_weightconstraint_allparams.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(learning_rate=.00105),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "param_model_weightconstraint_allparams.fit(X_train, y_train, epochs=14,\n",
    "          batch_size=33,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()  # Change variable \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "## Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a function reflecting the schema of your best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01), input_dim=784),\n",
    "        Dense(32, kernel_constraint=wc, activation=ReLU(negative_slope=.01)),\n",
    "        Dense(10, kernel_constraint=wc, activation=Softmax())\n",
    "        ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(learning_rate=.00105),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit and evaluate model and ensure results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2500/2500 - 5s - loss: 1.4268 - accuracy: 0.7103 - val_loss: 0.8791 - val_accuracy: 0.7503\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2500/2500 - 4s - loss: 0.8212 - accuracy: 0.7794 - val_loss: 0.8040 - val_accuracy: 0.7919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08c9a5dda0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=2, \n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.8040 - accuracy: 0.7919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8039919137954712, 0.7918999791145325]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model by using the function and cross reference with model.evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = create_model()  # Start with same architecture\n",
    "m.load_weights('./weights_best.h5')  # Load instead of train\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.7919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8039919137954712, 0.7918999791145325]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should match the prior evaluate cell\n",
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3427 - accuracy: 0.7056\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8570 - accuracy: 0.7729\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7935 - accuracy: 0.7876\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7537 - accuracy: 0.7973\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.7187 - accuracy: 0.8041\n",
      "WARNING:tensorflow:From /home/dondreojordan/Lambda/Unit4/Sprint2/Sprint2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/dondreojordan/Lambda/Unit4/Sprint2/Sprint2/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save entire model\n",
    "# i.e. both weights and architecture\n",
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [],
   "source": [
    "# If you closed the notebook right now would you be able to reload the model quickly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
